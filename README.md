# Model Summary-Lenta-ruT5-base

The transformer model for summarizing news articles. Additional training of the ruT5-base model was carried out on data obtained from the Russian news site "Lenta.ru".

Модель для суммаризации новостных статей. Дообучение модели ruT5-base проводилось на данных, полученных с русского новостного сайта "Lenta.ru".

## Model info
* **Language**: Russian
* **Type of transformer**: Text2Text Generation
* **Base model**: ruT5-base
* **Training**: Google Colab - T4 GPU, 4 epochs, lr 5e-5, 1024 tokens input length, 200 tokens input length

## Link
Link to [Huggingface](https://huggingface.co/sergeonsr/ruT5-base-test)
